import streamlit as st
import ollama

st.set_page_config(page_title="08A â€“ Playground (AusfÃ¼hrlich)", page_icon="ðŸŽ¯")
st.title("ðŸŽ¯ 08A â€“ Prompt Playground (AusfÃ¼hrlich)")

default_models = ["llama3.2", "llama3", "phi3", "mistral"]
model = st.selectbox("Modell", default_models, index=0)
temperature = st.slider("Temperatur", 0.0, 1.5, 0.7, 0.1)

prompt = st.text_area(
    "Prompt:",
    "Du bist ein hilfsbereiter Assistent. ErklÃ¤re in 3 SÃ¤tzen, wie man Ollama und Streamlit zusammen nutzt.",
    height=200,
)

if st.button("Prompt senden"):
    if not prompt.strip():
        st.warning("Bitte einen Prompt eingeben.")
    else:
        with st.spinner("LLM lÃ¤uft ..."):
            try:
                response = ollama.chat(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    options={"temperature": temperature},
                )
                st.subheader("Antwort")
                st.write(response["message"]["content"])
            except Exception as e:
                st.error("Fehler beim Prompt-Aufruf.")
                st.exception(e)

